[
["index.html", "データ分析（基礎）R分析資料 第1章 イントロダクション", " データ分析（基礎）R分析資料 石田 淳 関西学院大学社会学部2020-09-04 第1章 イントロダクション この資料は関西学院大学社会学部2020年秋学期「データ分析（基礎）」の補足資料として，講義内容をRを実行することで実感してもらうことを目的として作成している． 最新版のRとRStudioをインストールした環境，もしくはRStudio Cloud (https://rstudio.cloud)での利用を想定している． 本資料では，追加パッケージを必要としないbaseのみのRの機能を用いた分析の紹介を基本として，追加的にRのモダーンなパッケージ群であるtidyverseを前提とした分析コードも併せて紹介している． tidyverseを用いる際には，以下のコードを実行してあらかじめ環境にパッケージをインストールしておく必要がある． install.packages(&quot;tidyvese&quot;) その際，関連して必要となるパッケージのインストールを求められるかもしれない． "],
["記述統計学のおさらい.html", "第2章 記述統計学のおさらい 2.1 平均，分散，標準偏差 2.2 標準得点 2.3 共分散と相関係数", " 第2章 記述統計学のおさらい 2.1 平均，分散，標準偏差 平均は以下のように定義される． \\[\\bar{x}=\\frac{\\sum_{i=1}^nx_i}{n}=\\frac{x_1+x_2+\\cdots +x_n}{n}\\] Rで計算する場合は，定義通りsum(x)/length(x)とするか，組み込み関数を用いてmean(x)とする．講義ノート2.2.1の身長データの例． x &lt;- c(152.8, 150.1, 182.0, 163.2, 167.3, 160.2, 164.9, 161.4, 179.9, 172.2) sum(x)/length(x) ## [1] 165.4 mean(x) ## [1] 165.4 平均の特性については平均を実感するも参照のこと． 分散の定義は以下の通りである． \\[\\hat{\\sigma}^2=\\frac{1}{n}\\sum_{i=1}^n (x_i-\\bar{x})^2=\\frac{(x_1-\\bar{x})^2+(x_2-\\bar{x})^2+\\cdots+(x_n-\\bar{x})^2}{n}\\] Rのデフォルトの分散関数var(x)は\\(n-1\\)で割る不偏分散である．講義ノートの定義の分散を計算させたい場合は，定義に基づく計算をそのまま行うか，var(x)に\\((n-1)/n\\)を掛ければよい． mean((x-mean(x))^2) ## [1] 97.664 (length(x)-1)/length(x) * var(x) ## [1] 97.664 標準偏差は分散のルートを取ったものである． \\[\\hat{\\sigma}=\\sqrt{\\hat{\\sigma}^2}=\\sqrt{\\frac{1}{n}\\sum_{i=1}^n (x_i-\\bar{x})^2}\\] Rのデフォルトの標準偏差関数はsd(x)であり，これは不偏分散のルートである． sqrt(mean((x-mean(x))^2)) ## [1] 9.88251 sqrt((length(x)-1)/length(x)) * sd(x) ## [1] 9.88251 分散の特性についてはばらつきを実感するも参照のこと． 2.2 標準得点 Rでscale(x)をもちいてベクトルを一括して標準得点に変換できる．ただし，標準偏差は\\(n-1\\)でわる定義を採用している． \\[z_i=\\frac{x_i-\\bar{x}}{\\hat{\\sigma}_x}\\] x_scaled &lt;- scale(x) as.vector(x_scaled) ## [1] -1.2095520 -1.4687417 1.5935368 -0.2111916 0.1823928 -0.4991802 ## [7] -0.0479981 -0.3839848 1.3919448 0.6527741 mean(x_scaled) ## [1] -5.412337e-16 sd(x_scaled) ## [1] 1 標準化については標準化を実感するも参照のこと． 2.3 共分散と相関係数 2変数の関係を散布図で確認する． x &lt;- c(152.8,150.1,182,163.2,167.3,160.2,164.9,161.4,179.9,172.2) y &lt;- c(56.3,52.1,85.6,66.8,74.2,58.1,61.9,55.1,70.5,64.1) plot(x,y) また，tidyverseに含まれるggplot2で散布図を書くと以下のようになる．パッケージを用いる場合は，先にlibrary(tidyverse)を実行してパッケージを呼び出しておく． library(tidyverse) ## -- Attaching packages --------------- tidyverse 1.3.0 -- ## √ ggplot2 3.3.0 √ purrr 0.3.4 ## √ tibble 3.0.1 √ dplyr 0.8.5 ## √ tidyr 1.0.3 √ stringr 1.4.0 ## √ readr 1.3.1 √ forcats 0.5.0 ## -- Conflicts ------------------ tidyverse_conflicts() -- ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() tibble(x = c(152.8,150.1,182,163.2,167.3,160.2,164.9,161.4,179.9,172.2), y = c(56.3,52.1,85.6,66.8,74.2,58.1,61.9,55.1,70.5,64.1)) %&gt;% ggplot() + geom_point(aes(x = x, y = y)) 次に，共分散を計算する． \\[\\begin{align*} c_{xy}&amp;=\\frac{1}{n}\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y}) \\\\ &amp;=\\frac{(x_1-\\bar{x})(y_1-\\bar{y})+(x_2-\\bar{x})(y_2-\\bar{y})+\\cdots+(x_n-\\bar{x})(y_n-\\bar{y})}{n} \\nonumber \\end{align*}\\] Rで共分散はcov(x, y)であり，\\(n-1\\)でわる定義を採用している． mean((x-mean(x))*(y-mean(y))) ## [1] 81.313 cov(x,y)*(length(x)-1)/length(x) ## [1] 81.313 相関係数は，標準化した2変数の共分散であり， \\[r_{xy}=\\frac{c_{xy}}{\\hat{\\sigma}_x\\hat{\\sigma}_y}\\] で計算できる．Rでは相関係数関数cor(x,y)が用意されている．公式通りcov(x,y)/(sd(x)*sd(y))としてもよい（基準化されている値なので\\(n\\)で割るか\\(n-1\\)で割るかは関係ない）． cov(x,y)/(sd(x)*sd(y)) ## [1] 0.8496357 cor(x,y) ## [1] 0.8496357 "],
["推測統計学の考え方.html", "第3章 推測統計学の考え方 3.1 データ 3.2 ランダム・サンプリング 3.3 ランダム・サンプリングの繰り返し 3.4 バイアスのあるサンプリングの場合", " 第3章 推測統計学の考え方 ここでは無作為抽出（ランダム．サンプリング）による統計的推測の威力を感じてみよう．まずは細かいことは置いておいて感覚を大づかみしてみよう． 3.1 データ 真の分布（母集団分布）が平均170，分散100の正規分布であるとしよう．ふつう，調査の段階ではこの真の分布はわかっていない．標本（サンプル）から真の分布を推測するのが統計的推測である． curve(dnorm(x, 170, 10), xlim=c(140,200),col=&quot;red&quot;, lwd = 2) 3.2 ランダム・サンプリング 真の分布からサンプルサイズ10のサンプルをランダム・サンプリングする． set.seed(8931) n&lt;-10 sdata&lt;-rnorm(n, 170, 10) サンプルのヒストグラムは以下のようになる． hist(sdata, col = &quot;skyblue&quot;) サンプルの平均と分散は以下のようになる． mean(sdata) ## [1] 173.4489 var(sdata) ## [1] 126.2969 3.3 ランダム・サンプリングの繰り返し 真の分布からサンプルサイズ10のランダム・サンプルの平均をとる操作を10000回繰り返す． r&lt;-10000 rsdata&lt;-replicate(r,mean(rnorm(n, 170, 10))) そのデータのヒストグラムは以下のようになる． hist(rsdata, freq = FALSE, col = &quot;skyblue&quot;) lines(density(rsdata), col = &quot;red&quot;, lwd = 2) そのデータの平均と分散は以下のようになる． mean(rsdata) ## [1] 169.9568 var(rsdata) ## [1] 10.08717 ランダム・サンプリング平均の繰り返しデータの平均は真の分布の平均をよく近似しているようだ（ここで，平均という言葉が3回出てくることに注意）． ところで，ランダム・サンプリング平均の繰り返しデータから，真の分布の分散を推定する場合は以下の公式を使う． n*var(rsdata) ## [1] 100.8717 3.4 バイアスのあるサンプリングの場合 真の分布の中でも低めの値がサンプリングされやすいバイアスのあるサンプリングを考えてみよう． n&lt;-10 biased_sdata&lt;-sample(sort(rnorm(n*10, 170, 10))[1:n*5],n) hist(biased_sdata, col = &quot;skyblue&quot;) mean(biased_sdata) ## [1] 162.483 var(biased_sdata) ## [1] 42.6229 バイアスのあるサンプリングをr回繰り返す． r&lt;-1000 biased_rsdata&lt;-replicate(r,mean(sample(sort(rnorm(n*10, 170, 10))[1:n*5],n))) そのデータのヒストグラムは以下のようになる． hist(biased_rsdata, freq = FALSE, col = &quot;skyblue&quot;) lines(density(biased_rsdata), col = &quot;blue&quot;, lwd = 2) そのデータの平均と分散は以下のようになる． mean(biased_rsdata) ## [1] 163.0292 var(biased_rsdata) ## [1] 1.274754 真の分布の平均とずれがあるようだ． 最後にランダム・サンプリング（赤）とバイアスのあるサンプリング（青）の平均の分布を比較してみる． hist(biased_rsdata, freq = FALSE, col = &quot;#0000ff40&quot;, border = &quot;#0000ff&quot;, breaks = 20,xlim = c(140, 200),main = &quot;&quot;) hist(rsdata, freq = FALSE, col = &quot;#ff00ff40&quot;, border = &quot;#ff00ff&quot;, breaks = 20,xlim = c(140, 200),add=TRUE) lines(density(biased_rsdata), col = &quot;blue&quot;, lwd = 2) lines(density(rsdata), col = &quot;red&quot;, lwd = 2) "],
["確率論の基礎.html", "第4章 確率論の基礎 4.1 コインを一回投げる 4.2 コインを二回投げる", " 第4章 確率論の基礎 ゆがみのないコインを繰り返し投げる試行をシミュレーションにより再現してみよう． まず，結果の再現性を確保するために，コンピュータに（疑似）乱数を発生させる際の「乱数の種」を設定しておく．同じシードであれば，同じ結果が帰ってくる． set.seed(8931) 次に，コイン投げ関数をsample関数を利用して作成する．表をH，裏をTとする． coin &lt;- function() { sample(c(&quot;H&quot;, &quot;T&quot;),1) } 4.1 コインを一回投げる コインを一回投げる． coin() ## [1] &quot;T&quot; コイン投げ試行を1000回行って結果の割合を見てみよう． table(replicate(1000,coin()))/1000 ## ## H T ## 0.505 0.495 それぞれ，確率の古典的定義の1/2に近似する値になった．試行回数\\(n\\)を増やしていくと割合は1/2に近づいて行くものと期待できる． 4.2 コインを二回投げる コインを二回投げた結果をHTなどと表記する． paste0(coin(),coin()) ## [1] &quot;HT&quot; 2回コイン投げ試行を1000回行って結果の割合を見てみよう． table(replicate(1000,paste0(coin(),coin())))/1000 ## ## HH HT TH TT ## 0.262 0.245 0.253 0.240 それぞれのコイン投げが独立であるとすると，2回コイン投げ試行の結果の確率は\\((1/2)^2=1/4\\)となることが期待される．シミュレーションの結果はそれに近似する結果になった． "],
["確率変数と確率分布.html", "第5章 確率変数と確率分布 5.1 二項分布 5.2 二項分布のグラフ 5.3 ggplot2で描く", " 第5章 確率変数と確率分布 ここでは，二項分布のグラフをRで描く方法を説明する． 5.1 二項分布 Rには，主要な確率分布の確率関数（連続の場合は確率密度関数）がすでに用意されている．二項分布はdbinom(x, size, prob)である．xが成功回数のベクトル，sizeは試行回数\\(n\\)，probは成功確率\\(p\\)を指定する． 5.2 二項分布のグラフ 基本的には，\\(n\\)(x&lt;-0:5の5の値)と\\(p\\)の値を変えて一つずつグラフを描けばよい． p&lt;-0.5 x&lt;-0:5 prob&lt;-dbinom(x, length(x)-1, p) names(prob)&lt;-x barplot(prob,col=&quot;skyblue&quot;) \\(p\\)を変えたグラフをまとめて描く． \\(n = 5\\) pvec&lt;-c(0.1,0.5,0.7) x&lt;-0:5 probs&lt;-sapply(pvec, function(p) dbinom(x, length(x)-1, p)) colnames(probs)&lt;-c(&quot;p=0.1&quot;,&quot;p=0.5&quot;,&quot;p=0.7&quot;) rownames(probs)&lt;-x barplot(t(probs),beside=TRUE, legend = TRUE, col=c(&quot;blue&quot;, &quot;red&quot;, &quot;green&quot;)) \\(n = 10\\) pvec&lt;-c(0.1,0.5,0.7) x&lt;-0:10 probs&lt;-sapply(pvec, function(p) dbinom(x, length(x)-1, p)) colnames(probs)&lt;-c(&quot;p=0.1&quot;,&quot;p=0.5&quot;,&quot;p=0.7&quot;) rownames(probs)&lt;-x barplot(t(probs),beside=TRUE, legend = TRUE, col=c(&quot;blue&quot;, &quot;red&quot;, &quot;green&quot;)) 5.3 ggplot2で描く モダンなグラフ描写をする場合は，ggplot2パッケージを用いるといいだろう．いくつかのパッケージをバンドルしたtidyverseパッケージを呼び出して使おう． library(tidyverse) x &lt;- 0:20 tibble( x = x, p01 = dbinom(x, length(x) - 1, 0.1), p05 = dbinom(x, length(x) - 1, 0.5), p07 = dbinom(x, length(x) - 1, 0.7) ) %&gt;% gather(key = p, value = prob, p01, p05, p07) %&gt;% ggplot(.,aes(x=x,y=prob,fill=p)) + geom_bar(stat = &quot;identity&quot;, position = &quot;dodge&quot;) + scale_x_continuous(breaks = x) + scale_fill_hue(name = &quot;p&quot;, labels = c(p03 = &quot;0.1&quot;, p05 = &quot;0.5&quot;, p07 = &quot;0.7&quot;)) "],
["大数の法則と中心極限定理.html", "第6章 大数の法則と中心極限定理 6.1 一様分布からのランダムサンプリング 6.2 ベータ分布\\(Beta(0.5,0.5)\\)からのランダムサンプリング 6.3 おまけggplotで書く", " 第6章 大数の法則と中心極限定理 大数の法則と中心極限定理を実感するために，ランダムサンプリングデータの標本平均（相加平均）がどのような分布になるかを観察しよう． 6.1 一様分布からのランダムサンプリング 一様分布\\(U(0,1)\\)から，サンプルサイズ\\(n=1,10,100,1000\\)のサンプルをとって標本平均を計算する．これを，それぞれ10000回繰り返す．赤線は中心極限定理による標本分布近似の理論的予想である． set.seed(8931) repdata1&lt;-replicate(10000,mean(runif(1,0,1))) repdata2&lt;-replicate(10000,mean(runif(10,0,1))) repdata3&lt;-replicate(10000,mean(runif(100,0,1))) repdata4&lt;-replicate(10000,mean(runif(1000,0,1))) hist(repdata1, prob=TRUE, breaks = seq(0,1,0.005), xlim=c(0,1), main = &quot;n=1&quot;, xlab =&quot;&quot;, col=&quot;skyblue&quot;) hist(repdata2, prob=TRUE, breaks = seq(0,1,0.005), xlim=c(0,1), main = &quot;n=10&quot;, xlab =&quot;&quot;, col=&quot;skyblue&quot;) curve(dnorm(x, mean=1/2, sd= sqrt(1/12)/sqrt(10)), type=&quot;l&quot;, col = &quot;red&quot;, lwd=2, add=T) hist(repdata3, prob=TRUE, breaks = seq(0,1,0.005), xlim=c(0,1), main = &quot;n=100&quot;, xlab =&quot;&quot;, col=&quot;skyblue&quot;) curve(dnorm(x, mean=1/2, sd= sqrt(1/12)/sqrt(100)), type=&quot;l&quot;, col = &quot;red&quot;, lwd=2, add=T) hist(repdata4, prob=TRUE, breaks = seq(0,1,0.005), xlim=c(0,1), main = &quot;n=1000&quot;, xlab =&quot;&quot;, col=&quot;skyblue&quot;) curve(dnorm(x, mean=1/2, sd= sqrt(1/12)/sqrt(1000)), type=&quot;l&quot;, col = &quot;red&quot;, add=T) 6.2 ベータ分布\\(Beta(0.5,0.5)\\)からのランダムサンプリング 同じことをよりゆがんだ分布としてベータ分布\\(Beta(0.5,0.5)\\)でもやってみる repdata5&lt;-replicate(10000,mean(rbeta(1,0.5,0.5))) repdata6&lt;-replicate(10000,mean(rbeta(10,0.5,0.5))) repdata7&lt;-replicate(10000,mean(rbeta(100,0.5,0.5))) repdata8&lt;-replicate(10000,mean(rbeta(1000,0.5,0.5))) hist(repdata5, prob=TRUE, breaks = seq(0,1,0.005), xlim=c(0,1), main = &quot;n=1&quot;, xlab =&quot;&quot;, col=&quot;skyblue&quot;) hist(repdata6, prob=TRUE, breaks = seq(0,1,0.005), xlim=c(0,1), main = &quot;n=10&quot;, xlab =&quot;&quot;, col=&quot;skyblue&quot;) curve(dnorm(x, mean=1/2, sd= sqrt(1/8)/sqrt(10)), type=&quot;l&quot;, col = &quot;red&quot;, lwd=2, add=T) hist(repdata7, prob=TRUE, breaks = seq(0,1,0.005), xlim=c(0,1), main = &quot;n=100&quot;, xlab =&quot;&quot;, col=&quot;skyblue&quot;) curve(dnorm(x, mean=1/2, sd= sqrt(1/8)/sqrt(100)), type=&quot;l&quot;, col = &quot;red&quot;, lwd=2, add=T) hist(repdata8, prob=TRUE, breaks = seq(0,1,0.005), xlim=c(0,1), main = &quot;n=1000&quot;, xlab =&quot;&quot;, col=&quot;skyblue&quot;) curve(dnorm(x, mean=1/2, sd= sqrt(1/8)/sqrt(1000)), type=&quot;l&quot;, col = &quot;red&quot;, lwd=2, add=T) 6.3 おまけggplotで書く 要tidyverse library(tidyverse) tibble(&quot;n=1&quot;=repdata1,&quot;n=10&quot;=repdata2, &quot;n=100&quot;=repdata3,&quot;n=1000&quot;=repdata4) %&gt;% pivot_longer(everything(), names_to = &quot;key&quot;, values_to = &quot;value&quot;) %&gt;% ggplot() + geom_histogram(aes(x = value, y =..density..), bins=200,fill=&quot;skyblue&quot;, color= &quot;black&quot;) + # geom_density(adjust = 4, colour=&#39;black&#39;, size=1.25) + facet_grid(key~.) "],
["標本と標本分布.html", "第7章 標本と標本分布 7.1 一様分布からの\\(z\\)値の標本分布 7.2 正規分布からの\\(t\\)値の標本分布 7.3 一様分布からの\\(t\\)値の標本分布", " 第7章 標本と標本分布 ここでは，標本平均の標本分布をシミュレーションによって確かめてみる． set.seed(8931) 7.1 一様分布からの\\(z\\)値の標本分布 一様分布\\(U(0,1)\\)から，サンプルサイズ\\(n=5,10,30,100\\)のサンプルをとる． 母平均\\(\\mu=1/2\\)，母分散\\(\\sigma^2=1/12\\)はわかっているので，標本平均\\(\\bar{X}\\)の\\(Z\\)値を \\[Z=\\frac{\\bar{X}-\\mu}{\\sqrt{\\sigma^2/n}}=\\frac{\\bar{X}-1/2}{\\sqrt{1/(12n)}}\\] によって算出する．理論的には，\\(n\\)が十分大きいとき，\\(Z\\)の分布は標準正規分布に近似するはずである． 以下，\\(n\\)を変えて検証する．赤は標準正規分布である． n1&lt;-5 repdata1&lt;-replicate(10000,runif(n1)) z1&lt;-apply(repdata1,2, function(x) { (mean(x)-1/2)/sqrt((1/12)/n1) }) hist(z1, prob=TRUE,xlim=c(-4,4), breaks=seq(-ceiling(max(abs(z1))),ceiling(max(abs(z1))),0.2), col=&quot;skyblue&quot;, main = paste(&quot;n =&quot;,n1)) # lines(density(z1,adjust=2),lwd=2) curve(dnorm(x,0,1),-4,4,col=&quot;red&quot;,lwd=2,add=TRUE) n2&lt;-10 repdata2&lt;-replicate(10000,runif(n2)) z2&lt;-apply(repdata2,2, function(x) { (mean(x)-1/2)/sqrt((1/12)/n2) }) hist(z2, prob=TRUE,xlim=c(-4,4), breaks=seq(-ceiling(max(abs(z2))),ceiling(max(abs(z2))),0.2), col=&quot;skyblue&quot;, main = paste(&quot;n =&quot;, n2)) # lines(density(z2,adjust=2)) curve(dnorm(x,0,1),-4,4,col=&quot;red&quot;,lwd=2,add=TRUE) n3&lt;-30 repdata3&lt;-replicate(10000,runif(n3)) z3&lt;-apply(repdata3,2, function(x) { (mean(x)-1/2)/sqrt((1/12)/n3) }) hist(z3, prob=TRUE,xlim=c(-4,4), breaks=seq(-ceiling(max(abs(z3))),ceiling(max(abs(z3))),0.2), col=&quot;skyblue&quot;, main = paste(&quot;n =&quot;, n3)) # lines(density(z3,adjust=2)) curve(dnorm(x,0,1),-4,4,col=&quot;red&quot;,lwd=2,add=TRUE) n4&lt;-100 repdata4&lt;-replicate(10000,runif(n4)) z4&lt;-apply(repdata4,2, function(x) { (mean(x)-1/2)/sqrt((1/12)/n4) }) hist(z4, prob=TRUE,xlim=c(-4,4), breaks=seq(-ceiling(max(abs(z4))),ceiling(max(abs(z4))),0.2), col=&quot;skyblue&quot;, main = paste(&quot;n =&quot;, n3)) # lines(density(z4,adjust=2)) curve(dnorm(x,0,1),-4,4,col=&quot;red&quot;,lwd=2,add=TRUE) \\(n=30\\)程度で，十分近似しているといえそうである． 7.2 正規分布からの\\(t\\)値の標本分布 つぎに，母平均\\(\\mu=1\\)，母分散\\(\\sigma^2=1\\)の正規分布\\(N(1,1)\\)からのサンプルで\\(t\\)値を算出する．ここでは，母平均は既知だが，母分散は未知と考え，不偏標本分散\\(S^2\\)で置き換える． \\[t=\\frac{\\bar{X}-\\mu}{\\sqrt{S^2/n}}=\\frac{\\bar{X}-1}{\\sqrt{S^2/n}}\\] 理論的には，\\(t\\)値は自由度\\(n-1\\)の\\(t\\)分布に近似し，\\(n\\)が十分に大きければ\\(t\\)値は標準正規分布に近似すると考えられる． 以下，\\(n\\)を変えて検証する．赤は標準正規分布，青は自由度\\(n-1\\)の\\(t\\)分布である． n5&lt;-5 repdata5&lt;-replicate(10000,rnorm(n5,1,1)) t5&lt;-apply(repdata5,2, function(x) { (mean(x)-1)*sqrt(n5)/sd(x) }) hist(t5, prob=TRUE,xlim=c(-6,6), breaks=seq(-ceiling(max(abs(t5))),ceiling(max(abs(t5))),0.2), col=&quot;skyblue&quot;, main = paste(&quot;n =&quot;, n5)) # lines(density(t5,adjust=2)) curve(dnorm(x,0,1),-6,6,col=&quot;red&quot;,lwd=2,add=TRUE) curve(dt(x,n5-1),-6,6,col=&quot;blue&quot;,lwd=2,add=TRUE) n6&lt;-10 repdata6&lt;-replicate(10000,rnorm(n6,1,1)) t6&lt;-apply(repdata6,2, function(x) { (mean(x)-1)*sqrt(n6)/sd(x) }) hist(t6, prob=TRUE,xlim=c(-4,4), breaks=seq(-ceiling(max(abs(t6))),ceiling(max(abs(t6))),0.2), col=&quot;skyblue&quot;, main = paste(&quot;n =&quot;, n6)) # lines(density(t6,adjust=2)) curve(dnorm(x,0,1),-4,4,col=&quot;red&quot;,lwd=2,add=TRUE) curve(dt(x,n6-1),-4,4,col=&quot;blue&quot;,lwd=2,add=TRUE) n7&lt;-30 repdata7&lt;-replicate(10000,rnorm(n7,1,1)) t7&lt;-apply(repdata7,2, function(x) { (mean(x)-1)*sqrt(n7)/sd(x) }) hist(t7, prob=TRUE,xlim=c(-4,4), breaks=seq(-ceiling(max(abs(t7))),ceiling(max(abs(t7))),0.2), col=&quot;skyblue&quot;, main = paste(&quot;n =&quot;, n7)) # lines(density(t7,adjust=2)) curve(dnorm(x,0,1),-4,4,col=&quot;red&quot;,lwd=2,add=TRUE) curve(dt(x,n7-1),-4,4,col=&quot;blue&quot;,lwd=2,add=TRUE) n8&lt;-100 repdata8&lt;-replicate(10000,rnorm(n8,1,1)) t8&lt;-apply(repdata8,2, function(x) { (mean(x)-1)*sqrt(n8)/sd(x) }) hist(t8, prob=TRUE,xlim=c(-4,4), breaks=seq(-ceiling(max(abs(t8))),ceiling(max(abs(t8))),0.2), col=&quot;skyblue&quot;, main = paste(&quot;n =&quot;, n8)) # lines(density(t8,adjust=2)) curve(dnorm(x,0,1),-4,4,col=&quot;red&quot;,lwd=2,add=TRUE) curve(dt(x,n8-1),-4,4,col=&quot;blue&quot;,lwd=2,add=TRUE) まず，\\(n=5,10\\)のときは，標準正規分布よりも\\(t\\)分布$のほうが近似がよい． \\(n=30\\)程度で，標準正規分布と\\(t\\)分布はほとんど等しくなり，経験密度関数との近似も高まる． 7.3 一様分布からの\\(t\\)値の標本分布 さいごに，一様分布\\(U(0,1)\\)からの\\(t\\)値の分布も確認する． \\[t=\\frac{\\bar{X}-\\mu}{\\sqrt{S^2/n}}=\\frac{\\bar{X}-1/2}{\\sqrt{S^2/n}}\\] 理論的には，\\(n\\)が十分大きくなると，\\(t\\)値は標準正規分布に近似するはずである． 以下，\\(n\\)を変えて検証する．赤は標準正規分布，青は自由度\\(n-1\\)の\\(t\\)分布である． t1&lt;-apply(repdata1,2, function(x) { (mean(x)-1/2)*sqrt(n1)/sd(x) }) hist(t1, prob=TRUE,xlim=c(-6,6), breaks=seq(-ceiling(max(abs(t1))),ceiling(max(abs(t1))),0.2), col=&quot;skyblue&quot;, main = paste(&quot;n =&quot;, n1)) # lines(density(t1,adjust=2)) curve(dnorm(x,0,1),-6,6,col=&quot;red&quot;,lwd=2,add=TRUE) curve(dt(x,n1-1),-6,6,col=&quot;blue&quot;,lwd=2,add=TRUE) t2&lt;-apply(repdata2,2, function(x) { (mean(x)-1/2)*sqrt(n2)/sd(x) }) hist(t2, prob=TRUE,xlim=c(-4,4), breaks=seq(-ceiling(max(abs(t2))),ceiling(max(abs(t2))),0.2), col=&quot;skyblue&quot;, main = paste(&quot;n =&quot;, n2)) # lines(density(t2,adjust=2)) curve(dnorm(x,0,1),-4,4,col=&quot;red&quot;,lwd=2,add=TRUE) curve(dt(x,n2-1),-4,4,col=&quot;blue&quot;,lwd=2,add=TRUE) t3&lt;-apply(repdata3,2, function(x) { (mean(x)-1/2)*sqrt(n3)/sd(x) }) hist(t3, prob=TRUE,xlim=c(-4,4), breaks=seq(-ceiling(max(abs(t3))),ceiling(max(abs(t3))),0.2), col=&quot;skyblue&quot;, main = paste(&quot;n =&quot;, n3)) # lines(density(t3,adjust=2)) curve(dnorm(x,0,1),-4,4,col=&quot;red&quot;,lwd=2,add=TRUE) curve(dt(x,n3-1),-4,4,col=&quot;blue&quot;,lwd=2,add=TRUE) # n4&lt;-100 # repdata4&lt;-replicate(10000,runif(n4)) t4&lt;-apply(repdata4,2, function(x) { (mean(x)-1/2)*sqrt(n4)/sd(x) }) hist(t4, prob=TRUE,xlim=c(-4,4), breaks=seq(-ceiling(max(abs(t4))),ceiling(max(abs(t4))),0.2), col=&quot;skyblue&quot;, main = paste(&quot;n =&quot;, n4)) # lines(density(t4,adjust=2)) curve(dnorm(x,0,1),-4,4,col=&quot;red&quot;,lwd=2,add=TRUE) curve(dt(x,n4-1),-4,4,col=&quot;blue&quot;,lwd=2,add=TRUE) 正規分布からの\\(t\\)値の標本分布と同様の傾向である． "],
["統計的推定1-点推定.html", "第8章 統計的推定(1): 点推定 8.1 データ 8.2 尤度・対数尤度 8.3 推定誤差", " 第8章 統計的推定(1): 点推定 ここでは，講義ノートの例に従って，最尤法を実際に試みてみる． 8.1 データ 1,0のベルヌーイ試行を10回繰り返したところ，以下のデータを得た． data&lt;-c(0,1,1,1,1,0,1,1,0,1) ここでは，独立同分布のベルヌーイ分布を確率モデルとして，ベルヌーイ分布のパラメータ\\(q\\)を最尤推定(maximum likelihood estimatin)によって推定する． \\[x_1,x_2,\\ldots,x_{n} \\sim_{iid} p(x|q) \\] \\[p(x_i|q) = q^{x_i}(1-q)^{1-x_i}\\] 8.2 尤度・対数尤度 尤度の関数を実装する．独立同分布の仮定より尤度は， \\[\\begin{align*} p(\\{x_i\\}|q)&amp;=\\prod_{i=1}^n p(x_i|q) \\\\ &amp;=q^{\\sum x_i}(1-q)^{n-\\sum x_i} \\end{align*}\\] となる． LL_Bern&lt;-function(x,q) { q^sum(x)*(1-q)^(length(x)-sum(x)) } plot(seq(0,1,0.01),LL_Bern(data,seq(0,1,0.01)),type=&quot;l&quot;, xlab=&quot;&quot;,ylab =&quot;&quot;,main=&quot;&quot;) 対数尤度は， \\[\\begin{align*} \\log p(\\{x_i\\}|q)&amp;=\\sum_{i=1}^n \\log p(x_i|q) \\\\ &amp;=\\sum_{i=1}^n x_i \\log q+ \\left(n-\\sum_{i=1}^n x_i\\right)\\log(1-q) \\end{align*}\\] となる． logLL_Bern&lt;-function(x,q) { sum(x)*log(q)+(length(x)-sum(x))*log(1-q) } plot(seq(0,1,0.01),logLL_Bern(data,seq(0,1,0.01)), type=&quot;l&quot;,xlab=&quot;&quot;,ylab =&quot;&quot;,main=&quot;&quot;) 尤度・対数尤度の最大化問題を解くと，最尤推定値が得られる． optimize(function(q) LL_Bern(data,q),c(0,1),maximum = TRUE) ## $maximum ## [1] 0.6999843 ## ## $objective ## [1] 0.002223566 optimize(function(q) logLL_Bern(data,q),c(0,1),maximum = TRUE) ## $maximum ## [1] 0.7000058 ## ## $objective ## [1] -6.108643 8.3 推定誤差 一般に，ベルヌーイ分布のパラメタ\\(q\\)のMLEは，標本平均である． \\[q_{\\mathrm{ML}}=\\bar{X}=\\frac{\\sum_{i=1}^nx_i}{n}\\] このとき，中心極限定理により，\\(q_{\\mathrm{ML}}\\)の標本分布は平均\\(q\\)，分散\\(q(1-q)/n\\)の正規分布に近似すると予想できる． このことを確かめるために，\\(q=0.7\\)のベルヌーイ分布から，\\(n=10\\)のサンプルを抜き出してMLEを計算する，これを\\(r=10000\\)回繰り返す（ブートストラップ法という）． q&lt;-0.7 n&lt;-10 r&lt;-10000 repdata&lt;-replicate(r,mean(rbinom(n,1,q))) hist(repdata, prob=TRUE,xlim=c(0,1), breaks=seq(-0.05,1.05,0.1),col=&quot;skyblue&quot;,main=&quot;&quot;) curve(dnorm(x,q,sqrt(q*(1-q)/n)),0,1,col=&quot;red&quot;,lwd=2,add=TRUE) repdataの平均は0.69944\\(\\approx q\\)であり，標準偏差は0.1444914\\(\\approx \\sqrt{q(1-q)/n}\\)となる． "],
["統計的推定2-区間推定.html", "第9章 統計的推定(2): 区間推定 9.1 正規分布からのランダムサンプリング 9.2 ランダムサンプリングの繰り返し", " 第9章 統計的推定(2): 区間推定 set.seed(8931) 9.1 正規分布からのランダムサンプリング \\(N(165,10)\\)から\\(n=10\\)のランダムサンプリングを行って95%信頼区間を推定する． ex&lt;-rnorm(10,165,10) m&lt;-mean(ex) ci&lt;-1.96*sd(ex)/sqrt(10) c(m-ci,m,m+ci) ## [1] 161.4834 168.4489 175.4144 9.2 ランダムサンプリングの繰り返し 95%信頼区間の推定を100回繰り返す． rdata&lt;-replicate(100,{ ex&lt;-rnorm(10,165,10) m&lt;-mean(ex) ci&lt;-1.96*sd(ex)/sqrt(10) c(m-ci,m,m+ci) }) rdata&lt;-data.frame(1:100,t(rdata)) colnames(rdata)&lt;-c(&quot;trials&quot;,&quot;minci&quot;,&quot;mean&quot;,&quot;maxci&quot;) head(rdata) ## trials minci mean maxci ## 1 1 158.5386 163.0471 167.5556 ## 2 2 158.0395 164.7257 171.4119 ## 3 3 159.9578 164.9774 169.9970 ## 4 4 157.2232 163.1067 168.9902 ## 5 5 153.2887 162.3171 171.3455 ## 6 6 157.3803 164.3814 171.3826 作図してみてみよう． matplot(rdata$trials, rdata[,c(&quot;minci&quot;,&quot;mean&quot;,&quot;maxci&quot;)], type=&quot;l&quot;) segments(0,165,100,165) 正答率を算出する． sum(rdata$minci&lt;165 &amp; rdata$maxci &gt; 165)/100 ## [1] 0.92 ggplot2でかっこよく作図する． library(ggplot2) ggplot(data = rdata, aes(x = mean ,y = trials)) + geom_point() + geom_errorbarh(aes(xmin=minci, xmax=maxci)) + geom_vline(xintercept = 165, color=&quot;red&quot;) 関数化（要gglpot2）．m: 正規分布の平均，s: 正規分布の標準偏差，n: サンプルサイズ，r: 繰り返し回数 CItest&lt;-function(m,s,n,r) { rdata&lt;-replicate(r,{ ex&lt;-rnorm(n,m,s) m&lt;-mean(ex) ci&lt;-1.96*sd(ex)/sqrt(n) c(m-ci,m,m+ci) }) rdata&lt;-data.frame(1:r,t(rdata)) colnames(rdata)&lt;-c(&quot;trials&quot;,&quot;minci&quot;,&quot;mean&quot;,&quot;maxci&quot;) sr&lt;-sum(rdata$minci&lt;m &amp; rdata$maxci &gt; m)/r cat(paste(&quot;正答率: &quot;,sr)) ggplot2::ggplot(data = rdata, aes(x = mean ,y = trials)) + geom_point() + geom_errorbarh(aes(xmin=minci, xmax=maxci)) + geom_vline(xintercept = m, color=&quot;red&quot;) } CItest(160,20,10,500) ## 正答率: 0.92 "],
["仮説検定1-仮説検定の考え方.html", "第10章 仮説検定(1): 仮説検定の考え方", " 第10章 仮説検定(1): 仮説検定の考え方 次章以降を参照． "],
["仮説検定2-母平均母比率の検定.html", "第11章 仮説検定(2): 母平均・母比率の検定 11.1 母平均の検定 11.2 母比率の検定", " 第11章 仮説検定(2): 母平均・母比率の検定 ここでは，母平均・母比率の検定を自力で行い，Rの組み込み関数と結果を比較する． set.seed(8931) 11.1 母平均の検定 平均170分散100の母集団正規分布\\(N(170,100)\\)からの\\(n=100\\)のサンプリングデータが得られたとする． d&lt;-rnorm(100,170,10) hist(d,col=&quot;skyblue&quot;) c(mean(d),sd(d)) ## [1] 169.46672 10.59732 母分散未知として，帰無仮説・対立仮説 \\[H_0: \\mu = \\mu_0,\\ \\ H_1: \\mu \\neq \\mu_0\\] として両側仮説検定を実施する． 帰無仮説のもとでの\\(t\\)値を算出する関数を定義する． \\[t=\\frac{\\bar{X}-\\mu_0}{S/\\sqrt{n}}\\] \\(\\mu_0=165\\)としたときの\\(t\\)値． t&lt;-function(data,mu0) { (mean(data)-mu0)/(sd(data)/sqrt(length(data))) } tstat&lt;-t(d,165) tstat ## [1] 4.214954 標準正規分布を仮定したときの\\(p\\)値． 2*(1-pnorm(abs(tstat))) ## [1] 2.498288e-05 \\(t\\)分布\\(t(n-1)\\)を仮定したときの\\(p\\)値． 2*(1-pt(abs(tstat),length(d)-1)) ## [1] 5.525124e-05 t.test関数を使って同じことをする． t.test(d, mu=165) ## ## One Sample t-test ## ## data: d ## t = 4.215, df = 99, p-value = 5.525e-05 ## alternative hypothesis: true mean is not equal to 165 ## 95 percent confidence interval: ## 167.3640 171.5695 ## sample estimates: ## mean of x ## 169.4667 \\(t\\)値ならびに\\(t\\)分布を仮定したときの\\(p\\)値が一致していることが確認できる． 帰無仮説\\(H_0: \\mu=165\\)のもとでの\\(t\\)値の分布を確認する． repdata&lt;-replicate(10000,t(rnorm(100,165,10),165)) hist(repdata,col=&quot;skyblue&quot;, prob=TRUE) curve(dnorm(x,0,1),-4,4,col=&quot;red&quot;,add=TRUE) 帰無仮説\\(H_0: \\mu=165\\)のもとで\\(t\\)値として4.2149543のような値が得られることはほとんどない． length(which(abs(repdata)&gt;tstat))/length(repdata) ## [1] 0 11.2 母比率の検定 ベルヌーイ分布\\(Bi(1,0.6)\\)からの\\(n=100\\)のサンプリングデータが得られたとする． d2&lt;-rbinom(100,1,0.6) hist(d2,xlim=c(-0.5,1.5),breaks=seq(-0.5,1.5,1),col=&quot;skyblue&quot;) 帰無仮説・対立仮説 \\[H_0: \\mu = \\mu_0,\\ \\ H_1: \\mu \\neq \\mu_0\\] のもとでの\\(z\\)値を算出する関数を定義する． \\[z=\\frac{\\hat{p}-p_0}{\\sqrt{p_0(1-p_0)/n}}\\] \\(p_0=0.5\\)としたときの\\(z\\)値を算出する． z&lt;-function(data,p0) { (mean(data)-p0)/sqrt(p0*(1-p0)/length(data)) } zstat&lt;-z(d2,0.5) zstat ## [1] 4 標準正規分布を仮定したときの\\(p\\)値． 2*(1-pnorm(abs(zstat))) ## [1] 6.334248e-05 prop.test関数を使って検定．ただし，prop.testでは，以下のzstat^2がカイ二乗分布\\(\\chi^2(1)\\)に従うことを利用して検定している． prop.test(sum(d2), length(d2), p = 0.5 , correct = FALSE) ## ## 1-sample proportions test without continuity correction ## ## data: sum(d2) out of length(d2), null probability 0.5 ## X-squared = 16, df = 1, p-value = 6.334e-05 ## alternative hypothesis: true p is not equal to 0.5 ## 95 percent confidence interval: ## 0.6041515 0.7810511 ## sample estimates: ## p ## 0.7 zstat^2 ## [1] 16 1-pchisq(zstat^2,1) ## [1] 6.334248e-05 "],
["仮説検定3-母平均の差母比率の差の検定.html", "第12章 仮説検定(3): 母平均の差・母比率の差の検定 12.1 母平均の差の検定（t検定）", " 第12章 仮説検定(3): 母平均の差・母比率の差の検定 ここでは，母平均の差・母比率の差の検定を自力で行い，Rの組み込み関数と結果を比較する． set.seed(8931) 12.1 母平均の差の検定（t検定） \\(X\\sim N(170,100)\\)と\\(Y\\sim N(160,100)\\)から，それぞれ\\(n=100\\)のサンプリングデータが得られたとする． X&lt;-rnorm(100,170,10) Y&lt;-rnorm(100,160,10) plotmin&lt;-floor(min(X,Y)/10)*10 plotmax&lt;-ceiling(max(X,Y)/10)*10 Xdens&lt;-hist(X, breaks=seq(plotmin,plotmax,5), plot = FALSE)$density Ydens&lt;-hist(Y, breaks=seq(plotmin,plotmax,5), plot = FALSE)$density hist(X,xlim=c(plotmin,plotmax),ylim=c(0,max(Xdens,Ydens)), breaks=seq(plotmin,plotmax,5), freq=FALSE,col=&quot;#FF00007F&quot;, main=&quot;&quot;, xlab=&quot;&quot; ) hist(Y,xlim=c(plotmin,plotmax),ylim=c(0,max(Xdens,Ydens)), breaks=seq(plotmin,plotmax,5), freq=FALSE,col=&quot;#0000FF7F&quot;,add=T) 帰無仮説 \\[H_0: \\mu_1 = \\mu_2\\] のもとでの\\(t\\)値を算出する関数を定義する． \\[t=\\frac{\\bar{X}-\\bar{Y}}{S\\sqrt{\\frac{1}{n}+\\frac{1}{m}}}\\] \\[S=\\sqrt{\\frac{(n-1)S_X^2+(m-1)S_Y^2}{n+m-2}}\\] \\(H_0\\)のもとでの\\(t\\)値． t&lt;-function(data1,data2) { n&lt;-length(data1) m&lt;-length(data2) s&lt;-sqrt(((n-1)*var(data1)+(m-1)*var(data2))/(n+m-2)) (mean(data1)-mean(data2))/(s*sqrt(1/n+1/m)) } tstat&lt;-t(X,Y) tstat ## [1] 8.062544 標準正規分布を仮定したときの\\(p\\)値． 2*(1-pnorm(abs(tstat))) ## [1] 6.661338e-16 \\(t\\)分布\\(t(n+m-2)\\)を仮定したときの\\(p\\)値． 2*(1-pt(abs(tstat),length(X)+length(Y)-2)) ## [1] 6.972201e-14 t.test関数を使って同じことをする． t.test(X,Y,var.equal = TRUE) ## ## Two Sample t-test ## ## data: X and Y ## t = 8.0625, df = 198, p-value = 6.977e-14 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 8.615876 14.195249 ## sample estimates: ## mean of x mean of y ## 169.4667 158.0612 \\(t\\)値ならびに\\(t\\)分布を仮定したときの\\(p\\)値が一致していることが確認できる． 帰無仮説帰無仮説 \\(H_0: \\mu_1 = \\mu_2\\)のもとでの\\(t\\)値の分布を確認する． repdata&lt;-replicate(10000,t(rnorm(100,165,10),rnorm(100,165,10))) hist(repdata,col=&quot;skyblue&quot;, prob=TRUE) curve(dnorm(x,0,1),-4,4,col=&quot;red&quot;,add=TRUE) 帰無仮説\\(H_0: \\mu_1 = \\mu_2\\)のもとで\\(t\\)値として8.0625444のような値が得られることはほとんどない． length(which(abs(repdata)&gt;tstat))/length(repdata) ## [1] 0 12.1.1 母比率の差の検定 ベルヌーイ分布\\(X_1\\sim Bi(1,0.6)\\), \\(X_2\\sim Bi(1,0.4)\\)から，それぞれ\\(n=100\\)のサンプリングデータが得られたとする． X1&lt;-rbinom(100,1,0.6) X2&lt;-rbinom(100,1,0.4) par(mfrow=c(1,2)) hist(X1,xlim=c(-0.5,1.5),breaks=seq(-0.5,1.5,1), freq=FALSE,col=&quot;#FF00007F&quot;,main=&quot;&quot;) hist(X2,xlim=c(-0.5,1.5),breaks=seq(-0.5,1.5,1), freq=FALSE,col=&quot;#0000FF7F&quot;,main=&quot;&quot;) 帰無仮説 \\[H_0: p_1-p_2=0\\] のもとでの\\(z\\)値を算出する関数を定義する． \\[z=\\frac{\\hat{p}_1-\\hat{p}_2}{\\sqrt{\\hat{p}(1-\\hat{p})\\left(\\frac{1}{n_1}+\\frac{1}{n_2}\\right)}}\\] \\[\\hat{p}=\\frac{n_1\\hat{p_1}+n_2\\hat{p}_2}{n1+n2}\\] 帰無仮説のもとでの\\(z\\)値． z&lt;-function(data1,data2) { n1&lt;-length(data1) n2&lt;-length(data2) p&lt;-(n1*mean(data1)+n2*mean(data2))/(n1+n2) (mean(data1)-mean(data2))/sqrt(p*(1-p)*(1/n1+1/n2)) } zstat&lt;-z(X1,X2) zstat ## [1] 3.535711 標準正規分布を仮定したときの\\(p\\)値． 2*(1-pnorm(abs(zstat))) ## [1] 0.0004066798 prop.test関数を使って検定．ただし，prop.testでは，zstat^2がカイ二乗分布\\(\\chi^2(1)\\)に従うことを利用して検定している． prop.test(c(sum(X1),sum(X2)),c(length(X1),length(X2)),correct = FALSE) ## ## 2-sample test for equality of proportions without continuity ## correction ## ## data: c(sum(X1), sum(X2)) out of c(length(X1), length(X2)) ## X-squared = 12.501, df = 1, p-value = 0.0004067 ## alternative hypothesis: two.sided ## 95 percent confidence interval: ## 0.1158176 0.3841824 ## sample estimates: ## prop 1 prop 2 ## 0.62 0.37 zstat^2 ## [1] 12.50125 1-pchisq(zstat^2,1) ## [1] 0.0004066798 "],
["回帰分析における推定と検定.html", "第13章 回帰分析における推定と検定 13.1 単回帰分析 13.2 重回帰分析", " 第13章 回帰分析における推定と検定 13.1 単回帰分析 carsデータを使う．散布図 plot(cars$speed,cars$dist) speedを独立変数，distを従属変数とする回帰分析を実行する． lm_cars&lt;-lm(dist ~ speed, data=cars) slm_cars&lt;-summary(lm_cars) slm_cars ## ## Call: ## lm(formula = dist ~ speed, data = cars) ## ## Residuals: ## Min 1Q Median 3Q Max ## -29.069 -9.525 -2.272 9.215 43.201 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -17.5791 6.7584 -2.601 0.0123 * ## speed 3.9324 0.4155 9.464 1.49e-12 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 15.38 on 48 degrees of freedom ## Multiple R-squared: 0.6511, Adjusted R-squared: 0.6438 ## F-statistic: 89.57 on 1 and 48 DF, p-value: 1.49e-12 \\(t\\)値を係数と標準誤差から計算してみる． t&lt;-slm_cars$coefficients[&quot;speed&quot;,&quot;Estimate&quot;]/slm_cars$coefficients[&quot;speed&quot;,&quot;Std. Error&quot;] t ## [1] 9.46399 2*(1-pt(abs(t),nrow(cars)-1-1)) ## [1] 1.489919e-12 回帰直線をプロット． plot(cars$speed,cars$dist,col=&quot;lightgrey&quot;) abline(coef=coef(lm_cars),col=&quot;red&quot;,lwd=2) 最適化optim関数を使って，自力で最小二乗法を実行する． sumsq&lt;-function(coef) sum((cars$dist-coef[[1]]-coef[[2]]*cars$speed)^2) optim(c(0,0),sumsq) ## $par ## [1] -17.571729 3.931832 ## ## $value ## [1] 11353.52 ## ## $counts ## function gradient ## 91 NA ## ## $convergence ## [1] 0 ## ## $message ## NULL 分散共分散から係数を求める． cov_cars&lt;-cov(cars) mean_speed&lt;-mean(cars$speed) mean_dist&lt;-mean(cars$dist) c(mean_dist-cov_cars[1,2]*mean_speed/cov_cars[1,1], cov_cars[1,2]/cov_cars[1,1]) ## [1] -17.579095 3.932409 13.2 重回帰分析 mtcarsデータを使う head(mtcars) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 hpとwtよりmpgを説明する． lm_mtcars &lt;- lm(mpg ~ hp + wt, data=mtcars) slm_mtcars&lt;-summary(lm_mtcars) slm_mtcars ## ## Call: ## lm(formula = mpg ~ hp + wt, data = mtcars) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.941 -1.600 -0.182 1.050 5.854 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 37.22727 1.59879 23.285 &lt; 2e-16 *** ## hp -0.03177 0.00903 -3.519 0.00145 ** ## wt -3.87783 0.63273 -6.129 1.12e-06 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.593 on 29 degrees of freedom ## Multiple R-squared: 0.8268, Adjusted R-squared: 0.8148 ## F-statistic: 69.21 on 2 and 29 DF, p-value: 9.109e-12 \\(t\\)値を確認する． t_hp&lt;-slm_mtcars$coefficients[&quot;hp&quot;,&quot;Estimate&quot;]/slm_mtcars$coefficients[&quot;hp&quot;,&quot;Std. Error&quot;] t_hp ## [1] -3.518712 2*(1-pt(abs(t_hp),nrow(mtcars)-2-1)) ## [1] 0.001451229 t_wt&lt;-slm_mtcars$coefficients[&quot;wt&quot;,&quot;Estimate&quot;]/slm_mtcars$coefficients[&quot;wt&quot;,&quot;Std. Error&quot;] t_wt ## [1] -6.128695 2*(1-pt(abs(t_wt),nrow(mtcars)-2-1)) ## [1] 1.119647e-06 \\(F\\)値も確認する． F&lt;-slm_mtcars$r.squared/(1-slm_mtcars$r.squared)*(nrow(mtcars)-2-1)/2 F ## [1] 69.21121 1-pf(F,2,nrow(mtcars)-2-1) ## [1] 9.109047e-12 以下参考．回帰係数を自力で求める． c.f 永田靖・棟近雅彦，2001，『多変量解析法入門』サイエンス社． X&lt;-cbind(rep(1,nrow(mtcars)),mtcars$hp,mtcars$wt) XX&lt;-t(X)%*%X Xy&lt;-t(X)%*% mtcars$mpg solve(XX) %*% Xy ## [,1] ## [1,] 37.22727012 ## [2,] -0.03177295 ## [3,] -3.87783074 "],
["講義ノートの図.html", "第14章 講義ノートの図", " 第14章 講義ノートの図 おまけとして講義ノートで用いた図のコードをおいておく．要tidyverse． library(tidyverse) Figure 2.1 tibble(age=c(rep(18,43),rep(19,55),rep(20,68),rep(21,21),rep(22,9),rep(23,4))) %&gt;% ggplot() + geom_histogram(aes(x = age),binwidth = 1, color =&quot;black&quot;, fill = &quot;skyblue&quot;) + scale_x_continuous(breaks=18:23) + theme_classic() Figure 2.2 tibble(x = c(152.8,150.1,182,163.2,167.3,160.2,164.9,161.4,179.9,172.2), y = c(56.3,52.1,85.6,66.8,74.2,58.1,61.9,55.1,70.5,64.1)) %&gt;% ggplot() + geom_point(aes(x = x, y = y)) + theme_classic() Figure 5.1 tibble(x = 1:6, y = rep(1/6,6)) %&gt;% ggplot(., aes(x=x)) + geom_linerange(aes(ymax=y), ymin=0, color=&quot;grey50&quot;) + geom_point( aes(y=y) ) + scale_x_continuous(breaks=1:6) + ylab(&quot;f(x)&quot;) + theme_classic() Figure 5.2 tibble(x = 2:12, y = c(1:6,5:1)/36 ) %&gt;% ggplot(., aes(x=x)) + geom_linerange(aes(ymax=y), ymin=0, color=&quot;grey50&quot;) + geom_point( aes(y=y) ) + scale_x_continuous(breaks=2:12) + ylab(&quot;f(x)&quot;) + theme_classic() Figure 5.3 tibble(x = c(-3.5, 3.5)) %&gt;% ggplot(aes(x)) + stat_function(fun = dnorm, args = list(mean = 0,sd = 1), size = 1) + geom_area(stat = &#39;function&#39;, fun = dnorm, fill = &#39;grey50&#39;, xlim = c(-0.5, -1.5), alpha = 0.3) + geom_hline(yintercept = 0) + scale_x_continuous(breaks = NULL) + scale_y_continuous(breaks = NULL) + annotate(&quot;segment&quot;, x=-0.5,xend=-0.5,y=dnorm(-0.5),yend=0) + annotate(&quot;segment&quot;, x=-1.5,xend=-1.5,y=dnorm(-1.5),yend=0) + annotate(&quot;text&quot;, x=-0.5, y=-0.02, parse=TRUE,label=paste(&quot;b&quot;)) + #italic(b) annotate(&quot;text&quot;, x=-1.5, y=-0.02, parse=TRUE,label=paste(&quot;a&quot;)) + annotate(&quot;text&quot;, x=-1, y=0.1, parse=TRUE, label=paste( &quot;integral(f(x) * dx, a, b)&quot;) ) + theme_void() Figure 5.4 x &lt;- 0:10 tibble( x = x, p01 = dbinom(x, length(x) - 1, 0.1), p05 = dbinom(x, length(x) - 1, 0.5), p07 = dbinom(x, length(x) - 1, 0.7) ) %&gt;% gather(key = p, value = prob, p01, p05, p07) %&gt;% ggplot(.,aes(x=x,y=prob,color=p, shape=p)) + geom_point() + geom_linerange(aes(ymax=prob), ymin=0, alpha=0.2) + # geom_bar(stat = &quot;identity&quot;, position = &quot;dodge&quot;) + scale_x_continuous(breaks = x) + scale_fill_hue(name = &quot;p&quot;, labels = c(p01 = &quot;0.1&quot;, p05 = &quot;0.5&quot;, p07 = &quot;0.7&quot;)) + ylab(&quot;f(x)&quot;) + theme_classic() + theme( legend.position = c(1, 1), legend.justification = c(&quot;right&quot;, &quot;top&quot;), legend.box.just = &quot;right&quot;, legend.margin = margin(6, 6, 6, 6) ) Figure 6.1 tibble(n=1:100, se=2.92/1:100) %&gt;% ggplot() + geom_line(aes(x=n,y=se), size = 1) + labs(x=&quot;n&quot;,y=expression(sigma/n)) + theme_classic() Figure 6.2 biplot &lt;- tibble() p &lt;- 0.3 for (t in c(5,10,50,100)) { tibble( n=rep(t,t+1), x=0:t/t, y=t*dbinom(0:t,t,p) ) %&gt;% bind_rows(biplot,.) -&gt; biplot } biplot %&gt;% mutate(n = factor(n)) %&gt;% ggplot(aes(x=x, y=y, color = n)) + geom_step(size = 1) + labs(x=&quot;x/n&quot;, y=&quot;nf(x)&quot;) + theme_classic() + theme( legend.position = c(0.95, 0.95), legend.justification = c(&quot;right&quot;, &quot;top&quot;), legend.box.just = &quot;right&quot;, legend.margin = margin(6, 6, 6, 6) ) Figure 6.3 biplot &lt;- tibble() p &lt;- 0.3 for (t in c(10,100,1000,10000)) { tibble( n=rep(t,t+1), x=(0:t - t*p)/sqrt(t*p*(1-p)), y=sqrt(t*p*(1-p))*dbinom(0:t,t,p) ) %&gt;% bind_rows(biplot,.) -&gt; biplot } biplot %&gt;% mutate(n = factor(n,labels = c(&quot;n=10^1&quot;, &quot;n=10^2&quot;, &quot;n=10^3&quot;, &quot;n=10^4&quot;)) ) %&gt;% ggplot(aes(x=x, y=y)) + geom_step() + xlim(c(-3,3)) + labs(x=&quot;z&quot;, y=&quot;g(z)&quot;) + facet_wrap(~n) + theme_classic() + theme(strip.background = element_blank()) ## Warning: Removed 6863 row(s) containing missing values (geom_path). Figure 6.4 ggplot(tibble(x = c(-5, 10)), aes(x = x)) + stat_function(fun = dnorm, args = list(0, 1), aes(colour = &quot;\\u03bc =0, \\u03c3^2 = 1&quot;), size = 1) + stat_function(fun = dnorm, args = list(1, 2), aes(colour = &quot;\\u03bc =1, \\u03c3^2 = 4&quot;), size = 1) + stat_function(fun = dnorm, args = list(2, 3), aes(colour = &quot;\\u03bc =2, \\u03c3^2 = 9&quot;), size = 1) + scale_x_continuous(name = &quot;y&quot;, breaks = seq(-5, 10, 1), limits=c(-5, 10)) + scale_y_continuous(name = &quot;h(y)&quot;) + #scale_colour_brewer(palette=&quot;Accent&quot;) + labs(colour = &quot;parameters&quot;) + theme_classic() + theme( legend.position = c(0.95, 0.95), legend.justification = c(&quot;right&quot;, &quot;top&quot;), legend.box.just = &quot;right&quot;, legend.margin = margin(6, 6, 6, 6) ) ## Warning: `mapping` is not used by stat_function() ## Warning: `mapping` is not used by stat_function() ## Warning: `mapping` is not used by stat_function() Figure 6.5 tibble(x = c(-3.5, 3.5)) %&gt;% ggplot(aes(x)) + stat_function(fun = dnorm, n = 1000, args = list(mean = 0,sd = 1), size = 1) + geom_area(stat = &#39;function&#39;, fun = dnorm, fill = &#39;grey50&#39;, xlim = c(-1, 1), alpha = 0.3) + geom_hline(yintercept = 0) + scale_x_continuous(breaks = NULL) + scale_y_continuous(breaks = NULL) + annotate(&quot;segment&quot;, x=-1,xend=-1,y=dnorm(-1),yend=0) + annotate(&quot;segment&quot;, x=1,xend=1,y=dnorm(1),yend=0) + annotate(&quot;text&quot;, x=-1, y=-0.02, parse=TRUE,label=paste(&quot;-1&quot;)) + annotate(&quot;text&quot;, x=1, y=-0.02, parse=TRUE,label=paste(&quot;1&quot;)) + annotate(&quot;text&quot;, x=0, y=0.1, parse=TRUE, label=paste(&quot;integral(g(z) * dx, -1, 1)&quot;)) + theme_void() Figure 7.1 ggplot(data_frame(x = c(-5, 10)), aes(x = x)) + stat_function(fun = dnorm, args = list(0, 1), aes(colour = &quot;N(0,1)&quot;), size = 1) + stat_function(fun = dnorm, args = list(1,2), aes(colour = &quot;N(1,4)&quot;), size = 1) + stat_function(fun = dnorm, args = list(2,3), aes(colour = &quot;N(2,9)&quot;), size = 1) + scale_x_continuous(name = &quot;x&quot;, breaks = seq(-4, 10, 2), limits=c(-5, 10)) + scale_y_continuous(name = &quot;h(x)&quot;) + labs(colour = &quot;distribution&quot;) + theme_classic() + theme( legend.position = c(0.95, 0.95), legend.justification = c(&quot;right&quot;, &quot;top&quot;), legend.box.just = &quot;right&quot;, legend.margin = margin(6, 6, 6, 6) ) ## Warning: `data_frame()` is deprecated as of tibble 1.1.0. ## Please use `tibble()` instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_warnings()` to see where this warning was generated. ## Warning: `mapping` is not used by stat_function() ## Warning: `mapping` is not used by stat_function() ## Warning: `mapping` is not used by stat_function() Figure 7.2 ggplot(data_frame(x = c(-4, 4)), aes(x = x)) + stat_function(fun = dnorm, args = list(0, 1), aes(colour = &quot;N(0,1)&quot;), size = 1) + stat_function(fun = dt, args = list(1), aes(colour = &quot;t(1)&quot;), size = 1) + stat_function(fun = dt, args = list(3), aes(colour = &quot;t(3)&quot;), size = 1) + stat_function(fun = dt, args = list(5), aes(colour = &quot;t(5)&quot;), size = 1) + scale_x_continuous(name = &quot;x&quot;, breaks = seq(-4, 4, 1), limits=c(-4, 4)) + scale_y_continuous(name = &quot;f(x)&quot;) + labs(colour = &quot;distribution&quot;) + theme_classic() + theme( legend.position = c(0.95, 0.95), legend.justification = c(&quot;right&quot;, &quot;top&quot;), legend.box.just = &quot;right&quot;, legend.margin = margin(6, 6, 6, 6) ) ## Warning: `mapping` is not used by stat_function() ## Warning: `mapping` is not used by stat_function() ## Warning: `mapping` is not used by stat_function() ## Warning: `mapping` is not used by stat_function() Figure 8.1 tibble( x = seq(0,1,0.01), L = sapply(seq(0,1,0.01), function(q) q^7*(1-q)^3) ) %&gt;% ggplot() + geom_line(aes(x=x,y=L), size = 1) + labs(x=&quot;p&quot;,y=&quot;L(p)&quot;) + theme_classic() Figure 8.2 tibble( x = seq(0,1,0.01), L = sapply(seq(0,1,0.01), function(q) 7*log(q) + 3*log(1-q)) ) %&gt;% ggplot() + geom_line(aes(x=x,y=L), size = 1) + labs(x=&quot;p&quot;,y=&quot;log L(p)&quot;) + theme_classic() Figure 8.3 tibble(x = c(-3, 5)) %&gt;% ggplot(aes(x)) + stat_function(fun = dnorm, args = list(0, 1), aes(colour = &quot;estimate A&quot;), size = 1) + stat_function(fun = dnorm, args = list(1.5, 1), aes(colour = &quot;estimate B&quot;), size = 1) + geom_hline(yintercept = 0) + annotate(&quot;segment&quot;, x=0,xend=0,y=dnorm(0),yend=0, linetype=&quot;dashed&quot;) + annotate(&quot;text&quot;, x=0, y=-0.02, parse=TRUE, label=paste(&quot;theta&quot;)) + labs(colour = &quot;&quot;) + theme_void() + theme( legend.position = c(0.95, 0.95), legend.justification = c(&quot;right&quot;, &quot;top&quot;), legend.box.just = &quot;right&quot;, legend.margin = margin(6, 6, 6, 6) ) ## Warning: `mapping` is not used by stat_function() ## Warning: `mapping` is not used by stat_function() Figure 8.4 tibble(x = c(-3, 3)) %&gt;% ggplot(aes(x)) + stat_function(fun = dnorm, args = list(0, 0.5), aes(colour = &quot;estimate A&quot;), size = 1) + stat_function(fun = dnorm, args = list(0, 1), aes(colour = &quot;estimate B&quot;), size = 1) + geom_hline(yintercept = 0) + annotate(&quot;segment&quot;, x=0,xend=0,y=dnorm(0, 0, 0.5), yend=0, linetype=&quot;dashed&quot;) + annotate(&quot;text&quot;, x=0, y=-0.02, parse=TRUE, label=paste(&quot;theta&quot;)) + labs(colour = &quot;&quot;) + theme_void() + theme( legend.position = c(0.95, 0.95), legend.justification = c(&quot;right&quot;, &quot;top&quot;), legend.box.just = &quot;right&quot;, legend.margin = margin(6, 6, 6, 6) ) ## Warning: `mapping` is not used by stat_function() ## Warning: `mapping` is not used by stat_function() Figure 9.1 CItest&lt;-function(m,s,n,r) { rdata&lt;-replicate(r,{ ex&lt;-rnorm(n,m,s) m&lt;-mean(ex) ci&lt;-1.96*sd(ex)/sqrt(n) c(m-ci,m,m+ci) }) rdata&lt;-data.frame(1:r,t(rdata)) colnames(rdata)&lt;-c(&quot;trials&quot;,&quot;minci&quot;,&quot;mean&quot;,&quot;maxci&quot;) sr&lt;-sum(rdata$minci&lt;m &amp; rdata$maxci &gt; m)/r cat(paste(&quot;正答率: &quot;,sr)) ggplot2::ggplot(data = rdata, aes(x = mean ,y = trials)) + geom_point() + geom_errorbarh(aes(xmin=minci, xmax=maxci)) + geom_vline(xintercept = m, color=&quot;red&quot;) + theme_classic() } CItest(160,20,10,100) ## 正答率: 0.97 Figure 9.2 tibble(x = c(-3.5, 3.5)) %&gt;% ggplot(aes(x)) + stat_function(fun = dnorm, n = 1000, args = list(mean = 0,sd = 1), size = 1) + geom_area(stat = &#39;function&#39;, fun = dnorm, fill = &#39;grey50&#39;, xlim = c(-3.5, -1.9), alpha = 0.3) + geom_area(stat = &#39;function&#39;, fun = dnorm, fill = &#39;grey50&#39;, xlim = c(1.9, 3.5), alpha = 0.3) + geom_hline(yintercept = 0) + scale_x_continuous(breaks = NULL) + scale_y_continuous(breaks = NULL) + annotate(&quot;segment&quot;, x=0,xend=0,y=dnorm(0, 0, 1), yend=0) + annotate(&quot;segment&quot;, x=-1.9,xend=-1.9,y=dnorm(-1.9),yend=0) + annotate(&quot;segment&quot;, x=1.9,xend=1.9,y=dnorm(1.9),yend=0) + annotate(&quot;text&quot;, x=-1.9, y=-0.02, parse=TRUE,label=paste(&quot;-z[alpha/2]&quot;)) + annotate(&quot;text&quot;, x=1.9, y=-0.02, parse=TRUE,label=paste(&quot;z[alpha/2]&quot;)) + annotate(&quot;text&quot;, x=2.15, y=0.02, parse=TRUE, label=paste(&quot;alpha/2&quot;)) + annotate(&quot;text&quot;, x=-2.15, y=0.02, parse=TRUE, label=paste(&quot;alpha/2&quot;)) + theme_void() Figure 10.1 tibble(x = c(-3.5, 3.5)) %&gt;% ggplot(aes(x)) + stat_function(fun = dnorm, n = 1000, args = list(mean = 0,sd = 1), size = 1) + geom_area(stat = &#39;function&#39;, fun = dnorm, fill = &#39;grey50&#39;, xlim = c(-3.5, -1.96), alpha = 0.3) + geom_area(stat = &#39;function&#39;, fun = dnorm, fill = &#39;grey50&#39;, xlim = c(1.96, 3.5), alpha = 0.3) + geom_hline(yintercept = 0) + scale_x_continuous(breaks = NULL) + scale_y_continuous(breaks = NULL) + annotate(&quot;segment&quot;, x=0,xend=0,y=dnorm(0, 0, 1), yend=0) + annotate(&quot;segment&quot;, x=-1.96,xend=-1.96,y=dnorm(-1.96),yend=0) + annotate(&quot;segment&quot;, x=1.96,xend=1.96,y=dnorm(1.96),yend=0) + annotate(&quot;text&quot;, x=-1.96, y=-0.02, parse=TRUE,label=paste(&quot;-1.96&quot;)) + annotate(&quot;text&quot;, x=1.96, y=-0.02, parse=TRUE,label=paste(&quot;1.96&quot;)) + theme_void() Figure 10.2 tibble(x = c(-3.5, 3.5)) %&gt;% ggplot(aes(x)) + stat_function(fun = dnorm, n = 1000, args = list(mean = 0,sd = 1), size = 1) + geom_area(stat = &#39;function&#39;, fun = dnorm, fill = &#39;grey50&#39;, xlim = c(1.645, 3.5), alpha = 0.3) + geom_hline(yintercept = 0) + scale_x_continuous(breaks = NULL) + scale_y_continuous(breaks = NULL) + annotate(&quot;segment&quot;, x=0,xend=0,y=dnorm(0, 0, 1), yend=0) + annotate(&quot;segment&quot;, x=1.645,xend=1.645,y=dnorm(1.645),yend=0) + annotate(&quot;text&quot;, x=1.645, y=-0.02, parse=TRUE,label=paste(&quot;1.645&quot;)) + theme_void() Figure 13.1 set.seed(8931) dat &lt;- tibble(x=runif(100, 0, 50), y=rnorm(100, x + 10, 10)) dat %&gt;% ggplot(aes(x=x, y=y)) + geom_point() + geom_smooth(method=&quot;lm&quot;, fill=NA, lwd=1.5, fullrange=TRUE) + theme_classic() ## `geom_smooth()` using formula &#39;y ~ x&#39; summary(lm(y ~ x, dat)) ## ## Call: ## lm(formula = y ~ x, data = dat) ## ## Residuals: ## Min 1Q Median 3Q Max ## -26.6956 -7.0253 -0.8862 6.0086 21.5698 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 9.86720 2.02106 4.882 4.08e-06 *** ## x 0.96227 0.06952 13.842 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 10.48 on 98 degrees of freedom ## Multiple R-squared: 0.6616, Adjusted R-squared: 0.6582 ## F-statistic: 191.6 on 1 and 98 DF, p-value: &lt; 2.2e-16 Figure 13.2 dat &lt;- tibble(x=runif(200, 0, 50), y=rnorm(200, x + 10, 10)) breaks &lt;- c(10, 20, 30, 40, 50) norm &lt;- tibble() for (t in breaks) { br = seq(qnorm(0.005,t + 10,10),qnorm(0.995,t + 10,10),length=200) tibble(x=t-dnorm(br,t + 10,10)*100, y=br, b=t) %&gt;% bind_rows(norm,.) -&gt; norm } dat %&gt;% ggplot(aes(x=x, y=y)) + geom_point() + geom_path(data=norm, aes(x, y, group=b), lwd=1.0, color = &quot;red&quot;) + geom_vline(xintercept=breaks, lty=2) + geom_abline(intercept = 10, slope = 1)+ theme_classic() "]
]
